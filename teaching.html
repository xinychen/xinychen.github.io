<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <link rel="stylesheet" href="style.css">
    <title>Xinyu Chen</title>

<!-- <style>
    /* Left border - full coverage */
    body::before {
        content: "";
        position: fixed;
        top: 0;
        left: 0;
        width: 220px;
        height: 100%;
        background: url('Images/China_land.jpg') left center/cover no-repeat;
        z-index: -1;
    }

    /* Right border - full coverage */
    body::after {
        content: "";
        position: fixed;
        top: 0;
        right: 0;
        width: 220px;
        height: 100%;
        background: url('Images/China_land.jpg') right center/cover no-repeat;
        z-index: -1;
    }

    /* Force header to respect layout */
    #header_wrapper {
        margin: 0 !important;
        padding: 0 !important;
        width: 100% !important;
    }

    /* Main content container */
    #page {
        margin: 0 250px;
        background: white;
    }

    /* Fix for menu bar */
    .menu {
        background: white; /* Match your center background */
        padding-left: 20px; /* Adjust as needed */
    }

    /* Ensure all content stays within borders */
    .main {
        width: 100%;
        max-width: 900px;
        margin: 0 auto;
    }
</style> -->


    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-26204762-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>


  </head>


  <body>
    <div id="page">
      <div id="header_wrapper">
        <div id="header" class="main">
          <ul class="menu">
            <li><a href="index.html">About Me</a></li>
            <li><a href="news.html"> News </a></li>
            <li><a href="publications.html">Publications</a></li>
            <li><a href="projects.html">Projects</a></li>
            <li><a href="talks.html">Talks</a></li>
            <!-- <li><a href="team.html">Team</a></li> -->
            <li><a href="service.html">Services</a></li>
            <li><a class="active" href="teaching.html">Teaching</a></li>
          </ul>
  <br>
          <script src="table_header.js"></script> </div>

      <div id="wrapper" class="main">
        <div id="content">
<br>
<br>
<br>
<br>

<h1>Teaching</h1>
<hr>
I enjoy writing some stories and posts for explaining mathematics and machine learning. We would like to highlight the importance of some principles such as "温故而知新，可以为师矣" and "三人行，必有我师焉". Your contibutions to our materials would be highly appreciated.

<!-- <h2> Teaching Activities</h2> -->

<br>

<h2> AI for Smart Cities</h2>



<br>


<h2> Scientific Computating for Data Intelligence</h2>

<ul>
  <li>
    <p> Reading Materials <br>
      <span>&#8226;</span> <a href="https://www.cvxgrp.org/nasa/">CVXPY Course at NASA</a> (Philipp Schiele, Steven Diamond, Parth Nobel, Akshay Agrawal) <br>
      <span>&#8226;</span> <a href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf">The Matrix Cookbook</a> (Kaare Brandt Petersen, Michael Syskind Pedersen) <br>
      <span>&#8226;</span> <a href="https://arxiv.org/abs/2501.14787">Matrix Calculus (for Machine Learning and Beyond)</a> (Paige Bright, Alan Edelman, Steven G. Johnson) <br>
      <span>&#8226;</span> <a href="https://stanford.edu/~boyd/cvxbook/bv_cvxslides.pdf">Convex Optimization</a> (Stephen Boyd, Lieven Vandenberghe) <br>
      <span>&#8226;</span> <a href="https://www.stat.berkeley.edu/~mmahoney/s25-stat260/">Randomized Linear Algebra, Optimization, and Large-Scale Learning</a> (Michael Mahoney) <br>
    </p>
  </li>
</ul>



<br>


<h2> Teaching Samples</h2>

<span>&#9835;</span> Definition, properties, and derivatives of matrix traces. [<a href="https://xinychen.github.io/slides/matrix_trace.pdf">Slides</a>] [<a href="https://xinychen.github.io/video/matrix_trace.mp4">Video</a>]
<br>
<span>&#9835;</span> The relevance of t-statistics for small sample sizes. [<a href="https://xinychen.github.io/slides/t_stat.pdf">Slides</a>]
<!-- <br>
<span>&#9675;</span> Kronecker product in matrix and tensor computations. (Under development) [<a href="https://xinychen.github.io/slides/kron_prod.pdf">Slides</a>] -->
<!-- <br>
<span>&#9675;</span> Derivatives and gradients in machine learning models. (Under development) [<a href="https://arxiv.org/pdf/1802.01528">Reference material</a>] -->
<br>
<span>&#9835;</span> Three rates of convergence on a sequence. [<a href="https://xinychen.github.io/slides/convergence_rate.pdf">Slides</a>] [<a href="https://bookdown.org/rdpeng/advstatcomp/rates-of-convergence.html">Reference material</a>]
<br>
<span>&#9835;</span> Fibonacci sequence & dynamic programming. [<a href="https://xinychen.github.io/slides/dyna_pro_fib.pdf">Slides</a>] [<a href="https://www.youtube.com/watch?v=Hdr64lKQ3e4">Reference material</a>]
<br>
<span>&#9835;</span> But what is the Orthogonal Procrustes Problem (OPP)? [<a href="https://xinychen.github.io/slides/opp.pdf">Slides</a>] [<a href="https://www.linkedin.com/posts/xinyu-chen-567827309_machinelearning-linearalgebra-optimization-activity-7342528515105255424-MPR7?utm_source=share&utm_medium=member_desktop&rcm=ACoAAE6cRF8BQkvfA7IP7Mvm_o4mZdFgioalmdc">LinkedIn</a>] <span style = "color: darkred;">600+ reactions</span>
<br>
<span>&#9835;</span> Interpretable time series autoregression. [<a href="https://xinychen.github.io/slides/essential_ar.pdf">Slides</a>]
<br>
<span>&#9835;</span> Intuitive understanding of tensor factorization formula. [<a href="https://xinychen.github.io/slides/mat_tensor.pdf">Slides</a>]
<br>
<span>&#9835;</span> Essential idea of sparse autoregression & periodicity quantification. [<a href="https://xinychen.github.io/slides/autoregression.pdf">Slides</a>]


<br>
<br>


<h2> Tutorials</h2>

<span>&#9835;</span> <b>Time series convolution</b> (e.g., circular convolution, convolution matrix, circulant matrix, discrete Fourier transform, and sparse regression). [<a href="https://spatiotemporal-data.github.io/posts/ts_conv/">Website</a>]
<br>

<br>
<br>


<h1>Reading Hub</h1>
<hr>
<br>

<span>&#9835;</span> [<b>BP20</b>] Sparse high-dimensional regression: Exact scalable algorithms and phase transitions. 
[<a href="https://benzhengli.github.io/slides/ExactL0.pdf">Slides</a>] (Creator: <a href="https://benzhengli.github.io/">Ben-Zheng Li</a>)
<br>
<span>&#9835;</span> [<b>DGW23</b>] High-dimensional portfolio selection with cardinality constraints. 
[<a href="https://benzhengli.github.io/slides/PortfolioSelection.pdf">Slides</a>] (Creator: <a href="https://benzhengli.github.io/">Ben-Zheng Li</a>)



<br>
<br>


<h1>Favoriate Books/Textbooks</h1>
<hr>

<h2>Computer Vision</h2>

<span>&#9835;</span> Per Christian Hansen, James G. Nagy, and Dianne P. O'Leary (2006). Deblurring images: Matrices, spectra, and filtering. SIAM. [<a href="https://xinychen.github.io/slides/deblurring_images.pdf">Book notes</a>] [<a href="https://github.com/xinychen/awesome-beamer/tree/main/reading-notes/deblurring-images-slides">LaTeX code</a>]
<br>
<span>&#9835;</span> Richard Szeliski (2022). Computer Vision: Algorithms and Applications. Springer. Second Edition. [<a href="http://szeliski.org/Book/">Book website</a>]
<br>
<br>

<h2>Machine Learning</h2>

<span>&#9835;</span> Carl Edward Rasmussen and Christopher K. I. Williams (2006). Gaussian Processes for Machine Learning. MIT Press. [<a href="https://gaussianprocess.org/gpml/">Book website</a>]
<br>
<span>&#9835;</span> Charu C. Aggarwal (2020). Linear Algebra and Optimization for Machine Learning. Springer. [<a href="https://tocit.ru/static/files/3ed7f8bf5f3b74f557a486038a2923d92b96774b07aeecf432d88975be46e9ff.pdf">PDF</a>]
<br>
<span>&#9835;</span> Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong (2020). Mathematics for Machine Learning. Cambridge University Press. [<a href="https://mml-book.github.io/">Book website</a>]
<br>
<span>&#9835;</span> Jean Gallier and Jocelyn Quaintance (2022). Algebra, topology, differential calculus, and optimization theory for computer science and machine learning. [<a href="https://www.cis.upenn.edu/~jean/math-deep.pdf">PDF</a>]
<br>
<span>&#9835;</span> Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar (2018). Foundations of Machine Learning. MIT Press. Second Edition. [<a href="https://cs.nyu.edu/~mohri/mlbook/">Book website</a>]
<br>
<span>&#9835;</span> Shai Shalev-Shwartz and Shai Ben-David (2014). Understanding Machine Learning: From Theory to Algorithms. Cambridge University Press. [<a href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf">PDF</a>]
<br>
<span>&#9835;</span> Andreas Lindholm, Niklas Wahlström, Fredrik Lindsten, and Thomas B. Schön (2022). Machine Learning: A First Course for Engineers and Scientists. [<a href="https://smlbook.org/book/sml-book-draft-latest.pdf">PDF</a>]
<br>
<span>&#9835;</span> Francis Bach (2024). Learning Theory from First Principles. MIT Press. [<a href="https://www.di.ens.fr/~fbach/ltfp_book.pdf">PDF</a>]
<br>
<span>&#9835;</span> Jeff Erickson (2019). Algorithms. [<a href="https://jeffe.cs.illinois.edu/teaching/algorithms/">Book website</a>] [<a href="https://github.com/jeffgerickson/algorithms">GitHub</a>]
<br>
<span>&#9835;</span> Mykel J. Kochenderfer, Tim A. Wheeler, and Kyle H. Wray (2020). Algorithms for Decision Making. MIT Press. [<a href="https://algorithmsbook.com/files/dm.pdf">PDF</a>]
<br>
<span>&#9835;</span> Tong Zhang (2023). Mathematical Analysis of Machine Learning Algorithms. Cambridge University Press. [<a href="https://tongzhang-ml.org/lt-book.html">Book website</a>]
<br>
<span>&#9835;</span> Brian Christian (2020). The Alignment Problem: Machine Learning and Human Values. W. W. Norton & Company. [<a href="https://brianchristian.org/the-alignment-problem/">Book website</a>]
<br>
<span>&#9835;</span> Christoph Molnar (2024). Interpretable Machine Learning: A Guide for Making Black Box Models Explainable. [<a href="https://christophm.github.io/interpretable-ml-book/">Book website</a>]
<br>
<span>&#9835;</span> Andreas Krause, Jonas Hübotter (2025). Probabilistic Artificial Intelligence. arXiv:2502.05244. [<a href="https://arxiv.org/pdf/2502.05244">PDF</a>]
<br>
<span>&#9835;</span> Grey Ballard, Tamara G. Kolda (2025). Tensor Decompositions for Data Science. [<a href="https://users.wfu.edu/ballard/pdfs/tensor_textbook.pdf">PDF</a>]
<br>
<br>

<h2>Deep Learning</h2>

<span>&#9835;</span> Christopher M. Bishop, Hugh Bishop (2024). Deep Learning: Foundations and Concepts. Springer. [<a href="https://www.bishopbook.com/">Book website</a>]
<br>
<span>&#9835;</span> Simon J.D. Prince (2023). Understanding Deep Learning. MIT Press. [<a href="https://udlbook.github.io/udlbook/">Book website</a>]
<br>
<span>&#9835;</span> Daniel A. Roberts, Sho Yaida, and Boris Hanin (2021). The Principles of Deep Learning Theory. [<a href="https://arxiv.org/pdf/2106.10165.pdf">PDF</a>]
<br>
<span>&#9835;</span> M. Weiler (2023). Equivariant and Coordinate Independent Convolutional Networks: A Guide Field Theory of Neural Networks. [<a href="https://maurice-weiler.gitlab.io/cnn_book/EquivariantAndCoordinateIndependentCNNs.pdf">PDF</a>]
<br>
<span>&#9835;</span> Michael M. Bronstein, Joan Bruna, Taco Cohen, Petar Velickovic (2021). Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges. [<a href="https://arxiv.org/pdf/2104.13478">PDF</a>]
<br>
<span>&#9835;</span> Philipp Petersen, Jakob Zech (2024). Mathematical Theory of Deep Learning. [<a href="https://arxiv.org/abs/2407.18384">PDF</a>]
<br>
<br>

<h2>Data Science</h2>

<span>&#9835;</span> Jesús Rogel-Salazar (2020). Advanced Data Science and Analytics with Python. CRC Press. [<a href="https://library.samdu.uz/files/f2a7ac872bd1e8ab6ab987ba07c0819b_Advanced%20Data%20Science%20and%20%20%20Analytics%20with%20Python.pdf">PDF</a>]
<br>
<span>&#9835;</span> Dirk P. Kroese, Zdravko I. Botev, Thomas Taimre, and Radislav Vaisman (2022). Data Science and Machine Learning: Mathematical and Statistical Methods. [<a href="https://people.smp.uq.edu.au/DirkKroese/DSML/DSML.pdf">PDF</a>]
<br>
<span>&#9835;</span> Giacomo Bonanno (2018). Game Theory. Second Edition. [<a href="http://irving.vassar.edu/faculty/gj/215/literature/GT_book-bonanno.pdf">PDF</a>]
<br>
<span>&#9835;</span> Vijay Kotu and Bala Deshpande (2019). Data Science: Concepts and Practice. Elsevier. Second Edition. [<a href="https://asolanki.co.in/wp-content/uploads/2019/04/Data-Science-Concepts-and-Practice-2nd-Edition-3.pdf">PDF</a>]
<br>
<br>

<h2>Optimization Techniques</h2>

<span>&#9835;</span> Stephen Boyd and Lieven Vandenberghe (2004). Convex Optimization. Cambridge University Press. [<a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">PDF</a>]
<br>
<span>&#9835;</span> Jorge Nocedal and Stephen J. Wright (2006). Numerical Optimization. Springer. [<a href="https://www.math.uci.edu/~qnie/Publications/NumericalOptimization.pdf">PDF</a>]
<br>
<span>&#9835;</span> B. Guenin, J. Konemann, and L. Tuncel (2014). A Gentle Introduction to Optimization. Cambridge University Press. [<a href="https://industri.fatek.unpatti.ac.id/wp-content/uploads/2019/03/116-A-Gentle-Introduction-to-Optimization-B.-Guenin-J.-K%C3%B6nemann-L.-Tun%C3%A7el-Edisi-1-2014.pdf">PDF</a>]
<br>
<span>&#9835;</span> Steven L. Brunton (2025). Optimization Bootcamp with Applications in Machine Learning, Control, and Inverse Problems. [<a href="https://faculty.washington.edu/sbrunton/OptimizationBootcamp.pdf">PDF</a>] [<a href="https://xinychen.github.io/slides/OptBootcamp.pdf">Notes</a>]
<br>
<br>

<h2>Control Theory</h2>

<span>&#9835;</span> H. J. van Waarde and M. K. Camlibel and H. L. Trentelman (2025). Data-Based Linear Systems and Control Theory. [<a href="https://henkvanwaarde.github.io/dblsct.html">Book website</a>]
<br>
<br>

<h2>Information Theory</h2>

<span>&#9835;</span> Yury Polyanskiy and Yihong Wu (2022). Information Theory: From Coding to Learning. [<a href="https://people.lids.mit.edu/yp/homepage/data/itbook-export.pdf">PDF</a>]
<br>
<span>&#9835;</span> Gabriel Peyre (2020). The Discrete Algebra of the Fourier Transform. [<a href="https://mathematical-tours.github.io/daft-sources/DAFT-EN.pdf">PDF</a>]
<br>
<span>&#9835;</span> Antonio Ortega (2022). Introduction to Graph Signal Processing. [<a href="https://doi.org/10.1017/9781108552349">Book chapters</a>]
<br>
<br>

<!-- <h1>Tutorial</h1>
<hr>

<h2> STDmodeling: Spatiotemporal Traffic Data Modeling</h2>

<p>
- Module 2 (Exercise) - Revision: Matrix and Tensor Factorization [<a href="https://xinychen.github.io/tutorial/mtf_exercise.pdf">PDF</a>] [<a href="https://github.com/xinychen/xinychen.github.io/blob/master/tutorial/mtf_exercise.tex">LaTeX code</a>]
</p>

<br>

<h2> Machine Learning & Mathematics</h2>

<p>
- Intuitive Understanding of Newton-Raphson Method [<a href="https://xinychen.github.io/tutorial/Newton_Raphson.pdf">PDF</a>] [<a href="https://github.com/xinychen/Newton-Raphson">LaTeX code</a>] <br>
- Using Conjugate Gradient to Solve Matrix Equations [<a href="https://medium.com/p/7f16cbae18a3">Blog post</a>] [<a href="https://github.com/xinychen/conjugate-gradient">LaTeX code</a>] <br>
</p> -->

<br>
<br>
<br>

</div>

 </body>
</html>
