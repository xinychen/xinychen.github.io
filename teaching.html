<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <link rel="stylesheet" href="style.css">
    <title>Xinyu Chen</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-26204762-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>


  </head>


  <body>
    <div id="page">
      <div id="header_wrapper">
        <div id="header" class="main">
          <ul class="menu">
            <li><a href="index.html">About Me</a></li>
            <li><a href="news.html"> News </a></li>
            <li><a href="publications.html">Publications</a></li>
            <li><a href="projects.html">Projects</a></li>
            <li><a href="talks.html">Talks</a></li>
            <li><a href="team.html">Team</a></li>
            <li><a href="ProfServ.html">Services</a></li>
            <li><a class="active" href="teaching.html">Teaching</a></li>
          </ul>
  <br>
          <script src="table_header.js"></script> </div>

      <div id="wrapper" class="main">
        <div id="content">
<br>
<br>
<br>
<br>

<h1>Teaching</h1>
<hr>
I would like to highlight the importance of some principles such as "温故而知新，可以为师矣" and "三人行，必有我师焉". Your contibutions to my materials would be highly appreciated.

<!-- <h2> Teaching Activities</h2> -->


<h2> Teaching Samples</h2>

<span>&#9675;</span> Definition, properties, and derivatives of matrix traces. March 31, 2024. [<a href="https://xinychen.github.io/slides/matrix_trace.pdf">Slides</a>] [<a href="https://xinychen.github.io/video/matrix_trace.mp4">Video</a>]
<br>
<span>&#9675;</span> The relevance of t-statistics for small sample sizes. December 6, 2024. [<a href="https://xinychen.github.io/slides/t_stat.pdf">Slides</a>]
<br>
<span>&#9675;</span> Kronecker product in matrix and tensor computations. (Under development) [<a href="https://xinychen.github.io/slides/kron_prod.pdf">Slides</a>]
<br>
<span>&#9675;</span> Derivatives and gradients in machine learning models. (Under development) [<a href="https://arxiv.org/pdf/1802.01528">Reference material</a>]

<br>
<br>

<h2> Tutorials</h2>

<span>&#9675;</span> Time series convolution (e.g., circular convolution, convolution matrix, circulant matrix, discrete Fourier transform, and sparse regression). [<a href="https://spatiotemporal-data.github.io/posts/ts_conv/">Website</a>]
<br>

<br>
<br>

<h1>Blog Post</h1>
<hr>
I enjoy writing some stories for explaining my research. The content includes spatial (geospatial) data science, machine learning, matrix computations, and high-dimensional data analysis.
<br>
<p>
<h2>2023</h2>
<!-- 38. Visualizing global water vapor patterns in Python. August 19, 2023. [<a href="https://medium.com/p/776bf08b3179">Link</a>]<br> -->
37. An introduction to Laplacian convolutional representation. July 22, 2023. [<a href="https://medium.com/@xinyu.chen/an-introduction-to-laplacian-convolutional-representation-e20109ac8b1a">Link</a>]<br>
36. Derivatives with circular convolution in machine learning. June 23, 2023. [<a href="https://medium.com/p/17d4474d1edc">Link</a>]<br>
35. Kronecker product: A tutorial. June 13, 2023. [<a href="https://medium.com/p/304502340f22">Link</a>]<br>
<!-- 34. Time-varying autoregression with tensor factorization. June 12, 2023. [<a href="https://medium.com/p/567ab4d53e7a">Link</a>]<br> -->
33. Low-rank matrix and tensor factorization for speed field reconstruction. March 9, 2023. [<a href="https://medium.com/p/bb4807cb93c5">Link</a>]<br>
32. Intuitive understanding of tensors in machine learning. January 21, 2023. [<a href="https://medium.com/p/33635c64b596">Link</a>]<br>
<!-- 31. Discovering fluid dynamics with time-varying autoregression. January 20, 2023. [<a href="https://medium.com/p/b75d23b23a62">Link</a>]<br> -->
<h2>2022</h2>
30. Low-rank Laplacian convolution model for color image inpainting. December 17, 2022. [<a href="https://medium.com/p/e8c5cdb3cc73">Link</a>]<br>
29. Low-rank Laplacian convolution model for time series imputation and image inpainting. December 10, 2022. [<a href="https://medium.com/p/a46dd88d107e">Link</a>]<br>
28. Circulant matrix nuclear norm minimization for image inpainting in Python. December 9, 2022. [<a href="https://medium.com/p/b98eb94d8e">Link</a>]<br>
27. Matrix factorization for image inpainting in Python. December 8, 2022. [<a href="https://medium.com/p/d7300e6afbfd">Link</a>]<br>
<!-- 26. Discrete convolution and fast Fourier transform explained and implemented step by step. October 19, 2022. [<a href="https://medium.com/p/83ff1809378d">Link</a>]<br> -->
25. Simple linear models for image deblurring. October 12, 2022. [<a href="https://medium.com/p/539316bd1f0">Link</a>]<br>
24. Visualizing station-level USA temperature data in Python. October 8, 2022. [<a href="https://medium.com/p/4f813fb9116a">Link</a>]<br>
23. Reinforce matrix factorization for time series modeling: Probabilistic sequential matrix factorization. October 5, 2022. [<a href="https://medium.com/p/873f4ca344de">Link</a>]<br>
22. Convolution nuclear norm minimization for time series modeling. October 3, 2022. [<a href="https://medium.com/p/377c56e49962">Link</a>]<br>
<!-- 21. Visualizing Germany energy consumption data in Python. September 12, 2022. [<a href="https://medium.com/@xinyu.chen/visualizing-germany-energy-consumption-data-in-python-200e7cc3e506">Link</a>]<br> -->
20. Reproducing dynamic mode decomposition on fluid flow data in Python. September 6, 2022. [<a href="https://medium.com/@xinyu.chen/reproducing-dynamic-mode-decomposition-on-fluid-flow-data-in-python-94b8d7e1f203">Link</a>] [<a href="https://github.com/xinychen/fluid-inpainting">Data</a>]<br>
19. Tensor autoregression: A multidimensional time series model. September 3, 2022. [<a href="https://medium.com/p/21681f696d79">Link</a>]<br>
18. Montreal bikeshare data analysis II: Visualizing bike trips on road networks. August 29, 2022. [<a href="https://medium.com/@xinyu.chen/montreal-bikeshare-data-analysis-ii-visualizing-bike-trips-on-road-networks-3d9ab7e5787c">Link</a>]<br>
17. Montreal bikeshare data analysis I: Bikeshare station visualization and analysis. August 25, 2022. [<a href="https://medium.com/p/f5bec23e72f0">Link</a>]<br>
16. Implementing Kronecker product decomposition with NumPy. June 20, 2022. [<a href = "https://medium.com/p/13f679f76347">Link</a>]<br>
<!-- 15. Visualizing global sea surface temperature data in Python. June 18, 2022. [<a href = "https://medium.com/p/21a6324df563">Link</a>]<br> -->
14. Forecasting multivariate time series with nonstationary temporal matrix factorization. April 25, 2022. [<a href="https://medium.com/p/4705df163fcf">Link</a>]<br>
13. Temporal matrix factorization for multivariate time series forecasting. March 20, 2022. [<a href="https://medium.com/p/b1c59faf05ea">Link</a>] <span style = "color: darkred;">5,000+ views</span><br>
12. Inpainting fluid dynamics with tensor decomposition (NumPy). March 15, 2022. [<a href="https://medium.com/p/d84065fead4d">Link</a>]<br>
11. Using conjugate gradient to solve matrix equations. February 23, 2022. [<a href="https://medium.com/p/7f16cbae18a3">Link</a>]<br>
10. Intuitive understanding of Newton-Raphson method. February 16, 2022. [<a href="https://medium.com/@xinyu.chen/intuitive-understanding-of-newton-raphson-method-19fff4fdf75d">Link</a>]<br>
<!-- 9. Awesome-LaTeX-drawing: A collection of academic drawing examples using LaTeX. February 14, 2022. [<a href="https://medium.com/@xinyu.chen/awesome-latex-drawing-a-collection-of-academic-drawing-examples-using-latex-e07916b2c860">Link</a>]<br> -->
8. Analyzing missing data problem in Uber movement speed data. February 14, 2022. [<a href="https://medium.com/@xinyu.chen/analyzing-missing-data-problem-in-uber-movement-speed-data-208d7a126af5">Link</a>]<br>
<h2>2021</h2>
7. Dynamic mode decomposition for spatiotemporal traffic speed time series in Seattle freeway. October 29, 2021. [<a href="https://towardsdatascience.com/dynamic-mode-decomposition-for-spatiotemporal-traffic-speed-time-series-in-seattle-freeway-b0ba97e81c2c#ce4e-5f7c3f01d622">Link</a>]<br>
6. Reduced-rank vector autoregressive model for high-dimensional time series forecasting. October 16, 2021. [<a href="https://towardsdatascience.com/reduced-rank-vector-autoregressive-model-for-high-dimensional-time-series-forecasting-bdd17df6c5ab">Link</a>] <span style = "color: darkred;">4,000+ views</span><br>
<!-- 5. Dynamic mode decomposition for multivariate time series forecasting. October 10, 2021. [<a href="https://towardsdatascience.com/dynamic-mode-decomposition-for-multivariate-time-series-forecasting-415d30086b4b">Link</a>] <span style = "color: darkred;">18,000+ views</span><br> -->
4. Generating random numbers and arrays in Matlab and Numpy. October 9, 2021. [<a href="https://towardsdatascience.com/generating-random-numbers-and-arrays-in-matlab-and-numpy-47dcc9997650">Link</a>]<br>
<!-- 3. Understanding Lyapunov equation through Kronecker product and linear equation. October 8, 2021. [<a href="https://towardsdatascience.com/understand-the-lyapunov-equation-through-kronecker-product-and-linear-equation-bfff9c1e59ab">Link</a>]<br> -->
<!-- 2. Matrix autoregressive model for multidimensional time series forecasting. October 3, 2021. [<a href="https://t.co/FMSUSc0Tce?amp=1">Link</a>] <span style = "color: darkred;">9,000+ views</span><br> -->
<h2>2020</h2>
1. Intuitive understanding of randomized singular value decomposition. July 1, 2020. [<a href="https://towardsdatascience.com/intuitive-understanding-of-randomized-singular-value-decomposition-9389e27cb9de">Link</a>] <span style = "color: darkred;">10,000+ views</span><br>
</p>

<br>
<br>

<h1>Favoriate Books/Textbooks</h1>
<hr>

<h2>Computer Vision</h2>

<span>&#9675;</span> Per Christian Hansen, James G. Nagy, and Dianne P. O'Leary (2006). Deblurring images: Matrices, spectra, and filtering. SIAM. [<a href="https://xinychen.github.io/slides/deblurring_images.pdf">Book notes</a>] [<a href="https://github.com/xinychen/awesome-beamer/tree/main/reading-notes/deblurring-images-slides">LaTeX code</a>]
<br>
<span>&#9675;</span> Richard Szeliski (2022). Computer Vision: Algorithms and Applications. Springer. Second Edition. [<a href="http://szeliski.org/Book/">Book website</a>]
<br>
<br>

<h2>Machine Learning</h2>

<span>&#9675;</span> Carl Edward Rasmussen and Christopher K. I. Williams (2006). Gaussian Processes for Machine Learning. MIT Press. [<a href="https://gaussianprocess.org/gpml/">Book website</a>]
<br>
<span>&#9675;</span> Charu C. Aggarwal (2020). Linear Algebra and Optimization for Machine Learning. Springer. [<a href="https://tocit.ru/static/files/3ed7f8bf5f3b74f557a486038a2923d92b96774b07aeecf432d88975be46e9ff.pdf">PDF</a>]
<br>
<span>&#9675;</span> Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong (2020). Mathematics for Machine Learning. Cambridge University Press. [<a href="https://mml-book.github.io/">Book website</a>]
<br>
<span>&#9675;</span> Jean Gallier and Jocelyn Quaintance (2022). Algebra, topology, differential calculus, and optimization theory for computer science and machine learning. [<a href="https://www.cis.upenn.edu/~jean/math-deep.pdf">PDF</a>]
<br>
<span>&#9675;</span> Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar (2018). Foundations of Machine Learning. MIT Press. Second Edition. [<a href="https://cs.nyu.edu/~mohri/mlbook/">Book website</a>]
<br>
<span>&#9675;</span> Shai Shalev-Shwartz and Shai Ben-David (2014). Understanding Machine Learning: From Theory to Algorithms. Cambridge University Press. [<a href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf">PDF</a>]
<br>
<span>&#9675;</span> Andreas Lindholm, Niklas Wahlström, Fredrik Lindsten, and Thomas B. Schön (2022). Machine Learning: A First Course for Engineers and Scientists. [<a href="https://smlbook.org/book/sml-book-draft-latest.pdf">PDF</a>]
<br>
<span>&#9675;</span> Francis Bach (2024). Learning Theory from First Principles. MIT Press. [<a href="https://www.di.ens.fr/~fbach/ltfp_book.pdf">PDF</a>]
<br>
<span>&#9675;</span> Jeff Erickson (2019). Algorithms. [<a href="https://jeffe.cs.illinois.edu/teaching/algorithms/">Book website</a>] [<a href="https://github.com/jeffgerickson/algorithms">GitHub</a>]
<br>
<span>&#9675;</span> Mykel J. Kochenderfer, Tim A. Wheeler, and Kyle H. Wray (2020). Algorithms for Decision Making. MIT Press. [<a href="https://algorithmsbook.com/files/dm.pdf">PDF</a>]
<br>
<span>&#9675;</span> Tong Zhang (2023). Mathematical Analysis of Machine Learning Algorithms. Cambridge University Press. [<a href="https://tongzhang-ml.org/lt-book.html">Book website</a>]
<br>
<span>&#9675;</span> Brian Christian (2020). The Alignment Problem: Machine Learning and Human Values. W. W. Norton & Company. [<a href="https://brianchristian.org/the-alignment-problem/">Book website</a>]
<br>
<span>&#9675;</span> Christoph Molnar (2024). Interpretable Machine Learning: A Guide for Making Black Box Models Explainable. [<a href="https://christophm.github.io/interpretable-ml-book/">Book website</a>]
<br>
<span>&#9675;</span> Andreas Krause, Jonas Hübotter (2025). Probabilistic Artificial Intelligence. arXiv:2502.05244. [<a href="https://arxiv.org/pdf/2502.05244">PDF</a>]
<br>
<br>

<h2>Deep Learning</h2>

<span>&#9675;</span> Christopher M. Bishop, Hugh Bishop (2024). Deep Learning: Foundations and Concepts. Springer. [<a href="https://www.bishopbook.com/">Book website</a>]
<br>
<span>&#9675;</span> Simon J.D. Prince (2023). Understanding Deep Learning. MIT Press. [<a href="https://udlbook.github.io/udlbook/">Book website</a>]
<br>
<span>&#9675;</span> Daniel A. Roberts, Sho Yaida, and Boris Hanin (2021). The Principles of Deep Learning Theory. [<a href="https://arxiv.org/pdf/2106.10165.pdf">PDF</a>]
<br>
<span>&#9675;</span> M. Weiler (2023). Equivariant and Coordinate Independent Convolutional Networks: A Guide Field Theory of Neural Networks. [<a href="https://maurice-weiler.gitlab.io/cnn_book/EquivariantAndCoordinateIndependentCNNs.pdf">PDF</a>]
<br>
<span>&#9675;</span> Michael M. Bronstein, Joan Bruna, Taco Cohen, Petar Velickovic (2021). Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges. [<a href="https://arxiv.org/pdf/2104.13478">PDF</a>]
<br>
<br>

<h2>Data Science</h2>

<span>&#9675;</span> Jesús Rogel-Salazar (2020). Advanced Data Science and Analytics with Python. CRC Press. [<a href="https://library.samdu.uz/files/f2a7ac872bd1e8ab6ab987ba07c0819b_Advanced%20Data%20Science%20and%20%20%20Analytics%20with%20Python.pdf">PDF</a>]
<br>
<span>&#9675;</span> Dirk P. Kroese, Zdravko I. Botev, Thomas Taimre, and Radislav Vaisman (2022). Data Science and Machine Learning: Mathematical and Statistical Methods. [<a href="https://people.smp.uq.edu.au/DirkKroese/DSML/DSML.pdf">PDF</a>]
<br>
<span>&#9675;</span> Giacomo Bonanno (2018). Game Theory. Second Edition. [<a href="http://irving.vassar.edu/faculty/gj/215/literature/GT_book-bonanno.pdf">PDF</a>]
<br>
<span>&#9675;</span> Vijay Kotu and Bala Deshpande (2019). Data Science: Concepts and Practice. Elsevier. Second Edition. [<a href="https://asolanki.co.in/wp-content/uploads/2019/04/Data-Science-Concepts-and-Practice-2nd-Edition-3.pdf">PDF</a>]
<br>
<br>

<h2>Optimization Problem</h2>

<span>&#9675;</span> B. Guenin, J. Konemann, and L. Tuncel (2014). A Gentle Introduction to Optimization. Cambridge University Press. [<a href="https://industri.fatek.unpatti.ac.id/wp-content/uploads/2019/03/116-A-Gentle-Introduction-to-Optimization-B.-Guenin-J.-K%C3%B6nemann-L.-Tun%C3%A7el-Edisi-1-2014.pdf">PDF</a>]
<br>
<br>

<h2>Information Theory</h2>

<span>&#9675;</span> Yury Polyanskiy and Yihong Wu (2022). Information Theory: From Coding to Learning. [<a href="https://people.lids.mit.edu/yp/homepage/data/itbook-export.pdf">PDF</a>]
<br>
<span>&#9675;</span> Gabriel Peyre (2020). The Discrete Algebra of the Fourier Transform. [<a href="https://mathematical-tours.github.io/daft-sources/DAFT-EN.pdf">PDF</a>]
<br>
<span>&#9675;</span> Antonio Ortega (2022). Introduction to Graph Signal Processing. [<a href="https://doi.org/10.1017/9781108552349">Book chapters</a>]
<br>
<br>

<!-- <h1>Tutorial</h1>
<hr>

<h2> STDmodeling: Spatiotemporal Traffic Data Modeling</h2>

<p>
- Module 2 (Exercise) - Revision: Matrix and Tensor Factorization [<a href="https://xinychen.github.io/tutorial/mtf_exercise.pdf">PDF</a>] [<a href="https://github.com/xinychen/xinychen.github.io/blob/master/tutorial/mtf_exercise.tex">LaTeX code</a>]
</p>

<br>

<h2> Machine Learning & Mathematics</h2>

<p>
- Intuitive Understanding of Newton-Raphson Method [<a href="https://xinychen.github.io/tutorial/Newton_Raphson.pdf">PDF</a>] [<a href="https://github.com/xinychen/Newton-Raphson">LaTeX code</a>] <br>
- Using Conjugate Gradient to Solve Matrix Equations [<a href="https://medium.com/p/7f16cbae18a3">Blog post</a>] [<a href="https://github.com/xinychen/conjugate-gradient">LaTeX code</a>] <br>
</p> -->

<br>
<br>
<br>

</div>

 </body>
</html>
